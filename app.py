import streamlit as st
from deepface import DeepFace
import cv2
import tempfile
import pandas as pd

st.set_page_config(page_title="Emotion Detection", page_icon="ğŸ­", layout="centered")
st.title("ğŸ­ Emotion Detection from Video")
st.write("Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Î­Î½Î± video ÎºÎ±Î¹ Î±Î½Î¹Ï‡Î½ÎµÏÏƒÏ„Îµ Ï„Î± ÎºÏ…ÏÎ¯Î±ÏÏ‡Î± ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î± ÎºÎ±ÏÎ­â€‘ÎºÎ±ÏÎ­.")

uploaded_file = st.file_uploader("ğŸ“¤ Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î­Î½Î± video", type=["mp4", "avi", "mov"])
if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    video_path = tfile.name

    st.video(video_path)  # preview Ï„Î¿Ï… video

    if st.button("ğŸ” Î•ÎºÎºÎ¯Î½Î·ÏƒÎ· Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚"):
        cap = cv2.VideoCapture(video_path)
        frame_count = 0
        emotions = []

        progress = st.progress(0)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1
            if frame_count % 10 == 0:
                try:
                    result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)
                    emotions.append(result[0]['dominant_emotion'])
                except Exception:
                    pass

            progress.progress(min(frame_count / total_frames, 1.0))

        cap.release()

        st.success("âœ… Î‘Î½Î¬Î»Ï…ÏƒÎ· ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!")
        df = pd.Series(emotions).value_counts()
        st.bar_chart(df)
